{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4fd9c11",
   "metadata": {},
   "source": [
    "# TP1 Word Embeddings  \n",
    "## Training Word2Vec on the Press Corpus (QUAERO_FrenchPress)\n",
    "\n",
    "In this notebook, we train **Word2Vec embeddings** on the **press-domain corpus**\n",
    "(QUAERO_FrenchPress).\n",
    "\n",
    "The goal is to compare:\n",
    "- embeddings learned from a **large, general-domain corpus**\n",
    "- with embeddings learned from a **small, medical-domain corpus**\n",
    "\n",
    "We follow the lab constraints:\n",
    "- Library: `gensim`\n",
    "- Models: **CBOW** and **Skip-gram**\n",
    "- Embedding dimension: **100**\n",
    "- min_count: **1**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573587b0",
   "metadata": {},
   "source": [
    "## Imports and Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b9dd025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from gensim.models import Word2Vec\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43efeac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press corpus path: /Users/ilyessais/Documents/Lab M2/Text Mining & Chatbots/text-mining-chatbots-lab3/TP_ISD2020/data/embeddings_corpus/QUAERO_FrenchPress/QUAERO_FrenchPress_traindev.ospl\n",
      "Embeddings will be saved in: /Users/ilyessais/Documents/Lab M2/Text Mining & Chatbots/text-mining-chatbots-lab3/TP_ISD2020/embeddings\n"
     ]
    }
   ],
   "source": [
    "CURRENT_DIR = os.getcwd()\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(CURRENT_DIR, \"../..\"))\n",
    "\n",
    "# Press corpus path\n",
    "PRESS_CORPUS_PATH = os.path.join(\n",
    "    PROJECT_ROOT,\n",
    "    \"data\",\n",
    "    \"embeddings_corpus\",\n",
    "    \"QUAERO_FrenchPress\",\n",
    "    \"QUAERO_FrenchPress_traindev.ospl\"\n",
    ")\n",
    "\n",
    "# Output directory\n",
    "EMBEDDINGS_DIR = os.path.join(PROJECT_ROOT, \"embeddings\")\n",
    "os.makedirs(EMBEDDINGS_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Press corpus path:\", PRESS_CORPUS_PATH)\n",
    "print(\"Embeddings will be saved in:\", EMBEDDINGS_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ccb148",
   "metadata": {},
   "source": [
    "## Load and Tokenize the Press Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2188099d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of press sentences: 38548\n",
      "Example tokenized sentence:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Patricia',\n",
       " 'Martin',\n",
       " ',',\n",
       " 'que',\n",
       " 'voici',\n",
       " ',',\n",
       " 'que',\n",
       " 'voilà',\n",
       " '!',\n",
       " 'oh',\n",
       " ',',\n",
       " 'bonjour',\n",
       " 'Nicolas',\n",
       " 'Stoufflet',\n",
       " '.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_tokenized_corpus(path):\n",
    "    sentences = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                tokens = line.split()\n",
    "                sentences.append(tokens)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "press_sentences = load_tokenized_corpus(PRESS_CORPUS_PATH)\n",
    "\n",
    "print(f\"Number of press sentences: {len(press_sentences)}\")\n",
    "print(\"Example tokenized sentence:\")\n",
    "press_sentences[0][:20]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6235e4ea",
   "metadata": {},
   "source": [
    "## Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3a36fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 100\n",
      "Min count: 1\n",
      "Window size: 5\n",
      "Epochs: 10\n",
      "Workers: 12\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters (same as medical corpus)\n",
    "EMBEDDING_DIM = 100\n",
    "MIN_COUNT = 1\n",
    "WINDOW_SIZE = 5\n",
    "EPOCHS = 10\n",
    "\n",
    "N_WORKERS = multiprocessing.cpu_count()\n",
    "\n",
    "print(\"Embedding dimension:\", EMBEDDING_DIM)\n",
    "print(\"Min count:\", MIN_COUNT)\n",
    "print(\"Window size:\", WINDOW_SIZE)\n",
    "print(\"Epochs:\", EPOCHS)\n",
    "print(\"Workers:\", N_WORKERS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7db059",
   "metadata": {},
   "source": [
    "## Train Word2Vec CBOW Model (Press)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2693b706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Word2Vec CBOW model on press corpus...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBOW training completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Word2Vec CBOW model on press corpus...\")\n",
    "\n",
    "w2v_press_cbow = Word2Vec(\n",
    "    sentences=press_sentences,\n",
    "    vector_size=EMBEDDING_DIM,\n",
    "    window=WINDOW_SIZE,\n",
    "    min_count=MIN_COUNT,\n",
    "    sg=0,             \n",
    "    workers=N_WORKERS,\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "\n",
    "print(\"CBOW training completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4149eed",
   "metadata": {},
   "source": [
    "## Save CBOW Model and Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b1f1be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBOW model saved to: /Users/ilyessais/Documents/Lab M2/Text Mining & Chatbots/text-mining-chatbots-lab3/TP_ISD2020/embeddings/word2vec_press_cbow.model\n",
      "CBOW vectors saved to: /Users/ilyessais/Documents/Lab M2/Text Mining & Chatbots/text-mining-chatbots-lab3/TP_ISD2020/embeddings/word2vec_press_cbow.vec\n"
     ]
    }
   ],
   "source": [
    "cbow_model_path = os.path.join(EMBEDDINGS_DIR, \"word2vec_press_cbow.model\")\n",
    "cbow_vectors_path = os.path.join(EMBEDDINGS_DIR, \"word2vec_press_cbow.vec\")\n",
    "\n",
    "w2v_press_cbow.save(cbow_model_path)\n",
    "w2v_press_cbow.wv.save_word2vec_format(cbow_vectors_path)\n",
    "\n",
    "print(\"CBOW model saved to:\", cbow_model_path)\n",
    "print(\"CBOW vectors saved to:\", cbow_vectors_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b2ea77",
   "metadata": {},
   "source": [
    "## Train Word2Vec Skip-gram Model (Press)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a983cf2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Word2Vec Skip-gram model on press corpus...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip-gram training completed.\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Word2Vec Skip-gram model on press corpus...\")\n",
    "\n",
    "w2v_press_sg = Word2Vec(\n",
    "    sentences=press_sentences,\n",
    "    vector_size=EMBEDDING_DIM,\n",
    "    window=WINDOW_SIZE,\n",
    "    min_count=MIN_COUNT,\n",
    "    sg=1,           \n",
    "    workers=N_WORKERS,\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "\n",
    "print(\"Skip-gram training completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fdce24",
   "metadata": {},
   "source": [
    "## Save Skip-gram Model and Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0037e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip-gram model saved to: /Users/ilyessais/Documents/Lab M2/Text Mining & Chatbots/text-mining-chatbots-lab3/TP_ISD2020/embeddings/word2vec_press_skipgram.model\n",
      "Skip-gram vectors saved to: /Users/ilyessais/Documents/Lab M2/Text Mining & Chatbots/text-mining-chatbots-lab3/TP_ISD2020/embeddings/word2vec_press_skipgram.vec\n"
     ]
    }
   ],
   "source": [
    "sg_model_path = os.path.join(EMBEDDINGS_DIR, \"word2vec_press_skipgram.model\")\n",
    "sg_vectors_path = os.path.join(EMBEDDINGS_DIR, \"word2vec_press_skipgram.vec\")\n",
    "\n",
    "w2v_press_sg.save(sg_model_path)\n",
    "w2v_press_sg.wv.save_word2vec_format(sg_vectors_path)\n",
    "\n",
    "print(\"Skip-gram model saved to:\", sg_model_path)\n",
    "print(\"Skip-gram vectors saved to:\", sg_vectors_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc02528",
   "metadata": {},
   "source": [
    "## Vocabulary Size Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bad926c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBOW vocabulary size: 39654\n",
      "Skip-gram vocabulary size: 39654\n"
     ]
    }
   ],
   "source": [
    "print(\"CBOW vocabulary size:\", len(w2v_press_cbow.wv))\n",
    "print(\"Skip-gram vocabulary size:\", len(w2v_press_sg.wv))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac4659a",
   "metadata": {},
   "source": [
    "## Semantic Sanity Check (Press Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba3a5fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most similar words to 'patient' (CBOW – Press):\n",
      "  représentaient  0.803\n",
      "  gras            0.797\n",
      "  gossip          0.785\n",
      "  onomatopéique   0.782\n",
      "  sciemment       0.781\n",
      "\n",
      "Most similar words to 'traitement' (CBOW – Press):\n",
      "  coût            0.830\n",
      "  collectif       0.811\n",
      "  financement     0.791\n",
      "  système         0.788\n",
      "  renforcement    0.788\n",
      "\n",
      "Most similar words to 'maladie' (CBOW – Press):\n",
      "  puissance       0.799\n",
      "  population      0.788\n",
      "  garantie        0.787\n",
      "  douleur         0.783\n",
      "  mondialisation  0.777\n",
      "\n",
      "Most similar words to 'solution' (CBOW – Press):\n",
      "  recette         0.814\n",
      "  règle           0.805\n",
      "  catastrophe     0.799\n",
      "  coïncidence     0.791\n",
      "  alternative     0.789\n",
      "\n",
      "Most similar words to 'jaune' (CBOW – Press):\n",
      "  maillot         0.864\n",
      "  Bou             0.864\n",
      "  cavalier        0.864\n",
      "  Perrot          0.853\n",
      "  Wen             0.852\n"
     ]
    }
   ],
   "source": [
    "test_words = [\"patient\", \"traitement\", \"maladie\", \"solution\", \"jaune\"]\n",
    "\n",
    "for word in test_words:\n",
    "    if word in w2v_press_cbow.wv:\n",
    "        print(f\"\\nMost similar words to '{word}' (CBOW – Press):\")\n",
    "        for w, s in w2v_press_cbow.wv.most_similar(word, topn=5):\n",
    "            print(f\"  {w:<15} {s:.3f}\")\n",
    "    else:\n",
    "        print(f\"\\nWord '{word}' not found in press vocabulary.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e7c04c",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we trained **Word2Vec CBOW and Skip-gram models**\n",
    "on the **press domain corpus (QUAERO_FrenchPress)**.\n",
    "\n",
    "Compared to the medical corpus:\n",
    "- the press corpus is **much larger**\n",
    "- the vocabulary is **significantly richer**\n",
    "- embeddings tend to capture **general-language semantics**\n",
    "\n",
    "These embeddings will be:\n",
    "- compared with medical embeddings in the semantic similarity notebook\n",
    "- evaluated for their impact on downstream NER performance in TP2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53de54c2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
