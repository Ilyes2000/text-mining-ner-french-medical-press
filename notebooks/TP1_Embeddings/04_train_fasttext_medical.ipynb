{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a351f5c",
   "metadata": {},
   "source": [
    "# TP1 Word Embeddings  \n",
    "## Training FastText on the Medical Corpus (QUAERO_FrenchMed)\n",
    "\n",
    "In this notebook, we train **FastText word embeddings** on the\n",
    "medical-domain corpus **QUAERO_FrenchMed**.\n",
    "\n",
    "Unlike Word2Vec, FastText uses **character n-grams**, allowing:\n",
    "- better handling of rare words\n",
    "- generation of embeddings for unseen words\n",
    "\n",
    "We follow the lab constraints:\n",
    "- Library: `gensim`\n",
    "- Model: **FastText (CBOW)**\n",
    "- Embedding dimension: **100**\n",
    "- min_count: **1**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18163e1f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a242bb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "from gensim.models import FastText\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "194505c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medical corpus path: /Users/ilyessais/Documents/Lab M2/Text Mining & Chatbots/text-mining-chatbots-lab3/TP_ISD2020/data/embeddings_corpus/QUAERO_FrenchMed/QUAERO_FrenchMed_traindev.ospl\n",
      "Embeddings directory: /Users/ilyessais/Documents/Lab M2/Text Mining & Chatbots/text-mining-chatbots-lab3/TP_ISD2020/embeddings\n"
     ]
    }
   ],
   "source": [
    "CURRENT_DIR = os.getcwd()\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(CURRENT_DIR, \"../..\"))\n",
    "\n",
    "MEDICAL_CORPUS_PATH = os.path.join(\n",
    "    PROJECT_ROOT,\n",
    "    \"data\",\n",
    "    \"embeddings_corpus\",\n",
    "    \"QUAERO_FrenchMed\",\n",
    "    \"QUAERO_FrenchMed_traindev.ospl\"\n",
    ")\n",
    "\n",
    "EMBEDDINGS_DIR = os.path.join(PROJECT_ROOT, \"embeddings\")\n",
    "os.makedirs(EMBEDDINGS_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Medical corpus path:\", MEDICAL_CORPUS_PATH)\n",
    "print(\"Embeddings directory:\", EMBEDDINGS_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d89887",
   "metadata": {},
   "source": [
    "## Load and Tokenize Medical Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecad8970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of medical sentences: 3021\n",
      "Example tokenized sentence:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['EMEA', '/', 'H', '/', 'C', '/', '551']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_tokenized_corpus(path):\n",
    "    sentences = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                sentences.append(line.split())\n",
    "    return sentences\n",
    "\n",
    "\n",
    "medical_sentences = load_tokenized_corpus(MEDICAL_CORPUS_PATH)\n",
    "\n",
    "print(f\"Number of medical sentences: {len(medical_sentences)}\")\n",
    "print(\"Example tokenized sentence:\")\n",
    "medical_sentences[0][:20]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070c5eec",
   "metadata": {},
   "source": [
    "## Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91c09ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 100\n",
      "Min count: 1\n",
      "Window size: 5\n",
      "Epochs: 10\n",
      "Workers: 12\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "MIN_COUNT = 1\n",
    "WINDOW_SIZE = 5\n",
    "EPOCHS = 10\n",
    "N_WORKERS = multiprocessing.cpu_count()\n",
    "\n",
    "print(\"Embedding dimension:\", EMBEDDING_DIM)\n",
    "print(\"Min count:\", MIN_COUNT)\n",
    "print(\"Window size:\", WINDOW_SIZE)\n",
    "print(\"Epochs:\", EPOCHS)\n",
    "print(\"Workers:\", N_WORKERS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8576fa92",
   "metadata": {},
   "source": [
    "## Train FastText (CBOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0b72ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training FastText CBOW model on medical corpus...\n",
      "FastText training completed.\n"
     ]
    }
   ],
   "source": [
    "print(\"Training FastText CBOW model on medical corpus...\")\n",
    "\n",
    "fasttext_medical = FastText(\n",
    "    sentences=medical_sentences,\n",
    "    vector_size=EMBEDDING_DIM,\n",
    "    window=WINDOW_SIZE,\n",
    "    min_count=MIN_COUNT,\n",
    "    sg=0,             # CBOW\n",
    "    workers=N_WORKERS,\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "\n",
    "print(\"FastText training completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbf1afe",
   "metadata": {},
   "source": [
    "## Save Model and Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd6253be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText model saved to: /Users/ilyessais/Documents/Lab M2/Text Mining & Chatbots/text-mining-chatbots-lab3/TP_ISD2020/embeddings/fasttext_medical_cbow.model\n",
      "FastText vectors saved to: /Users/ilyessais/Documents/Lab M2/Text Mining & Chatbots/text-mining-chatbots-lab3/TP_ISD2020/embeddings/fasttext_medical_cbow.vec\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(EMBEDDINGS_DIR, \"fasttext_medical_cbow.model\")\n",
    "vectors_path = os.path.join(EMBEDDINGS_DIR, \"fasttext_medical_cbow.vec\")\n",
    "\n",
    "fasttext_medical.save(model_path)\n",
    "fasttext_medical.wv.save_word2vec_format(vectors_path)\n",
    "\n",
    "print(\"FastText model saved to:\", model_path)\n",
    "print(\"FastText vectors saved to:\", vectors_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff54016",
   "metadata": {},
   "source": [
    "## Vocabulary Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ebb755c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText medical vocabulary size: 9104\n"
     ]
    }
   ],
   "source": [
    "print(\"FastText medical vocabulary size:\", len(fasttext_medical.wv))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd35e26d",
   "metadata": {},
   "source": [
    "## Semantic Check (Medical Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b230f92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most similar words to 'patient' (FastText – Medical):\n",
      "  Patient         0.999\n",
      "  tremblements    0.999\n",
      "  pansements      0.999\n",
      "  patiente        0.999\n",
      "  Tremblements    0.999\n",
      "\n",
      "Most similar words to 'traitement' (FastText – Medical):\n",
      "  Traitement      1.000\n",
      "  Taaitement      1.000\n",
      "  Allaitement     0.999\n",
      "  allaitement     0.999\n",
      "  traitements     0.999\n",
      "\n",
      "Most similar words to 'maladie' (FastText – Medical):\n",
      "  Maladie         1.000\n",
      "  malade          1.000\n",
      "  professionnelle 1.000\n",
      "  professionnel   1.000\n",
      "  hyrgathione     1.000\n",
      "\n",
      "Most similar words to 'solution' (FastText – Medical):\n",
      "  Dissolution     1.000\n",
      "  évolution       0.999\n",
      "  dilution        0.999\n",
      "  Solution        0.999\n",
      "  Evolution       0.999\n",
      "\n",
      "Most similar words to 'jaune' (FastText – Medical):\n",
      "  zone            1.000\n",
      "  Une             1.000\n",
      "  hexane          1.000\n",
      "  Rhône           1.000\n",
      "  crâne           1.000\n"
     ]
    }
   ],
   "source": [
    "test_words = [\"patient\", \"traitement\", \"maladie\", \"solution\", \"jaune\"]\n",
    "\n",
    "for word in test_words:\n",
    "    print(f\"\\nMost similar words to '{word}' (FastText – Medical):\")\n",
    "    for w, s in fasttext_medical.wv.most_similar(word, topn=5):\n",
    "        print(f\"  {w:<15} {s:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c5234d",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "FastText embeddings trained on the medical corpus:\n",
    "- capture **domain-specific terminology**\n",
    "- benefit from character n-grams\n",
    "- handle rare and unseen words better than Word2Vec\n",
    "\n",
    "These embeddings will be:\n",
    "- compared with Word2Vec embeddings\n",
    "- evaluated on semantic similarity\n",
    "- used in TP2 for NER experiments\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
