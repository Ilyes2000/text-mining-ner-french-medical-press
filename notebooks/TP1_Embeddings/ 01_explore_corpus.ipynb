{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a59c9ad",
   "metadata": {},
   "source": [
    "# TP1 Corpus Exploration  \n",
    "## Semantic Representations Word Embeddings\n",
    "\n",
    "**Objective**\n",
    "\n",
    "The goal of this notebook is to explore and analyze the corpora provided for TP1:\n",
    "- **QUAERO_FrenchMed** (medical domain, small corpus)\n",
    "- **QUAERO_FrenchPress** (general domain, large corpus)\n",
    "\n",
    "This exploration aims to:\n",
    "- understand corpus size and structure,\n",
    "- analyze vocabulary statistics,\n",
    "- compare medical vs non-medical language,\n",
    "- prepare the data for word embeddings training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d14597",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "887f2e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643aa243",
   "metadata": {},
   "source": [
    "## Paths Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03865597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medical corpus found: True\n",
      "Press corpus found: True\n"
     ]
    }
   ],
   "source": [
    "BASE_DATA_DIR = \"../../data/embeddings_corpus\"\n",
    "\n",
    "MEDICAL_CORPUS = os.path.join(\n",
    "    BASE_DATA_DIR,\n",
    "    \"QUAERO_FrenchMed\",\n",
    "    \"QUAERO_FrenchMed_traindev.ospl\"\n",
    ")\n",
    "\n",
    "PRESS_CORPUS = os.path.join(\n",
    "    BASE_DATA_DIR,\n",
    "    \"QUAERO_FrenchPress\",\n",
    "    \"QUAERO_FrenchPress_traindev.ospl\"\n",
    ")\n",
    "\n",
    "print(\"Medical corpus found:\", os.path.exists(MEDICAL_CORPUS))\n",
    "print(\"Press corpus found:\", os.path.exists(PRESS_CORPUS))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54487b08",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6c47111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_corpus(path):\n",
    "    \"\"\"\n",
    "    Load a corpus where: one sentence per line,tokens separated by spaces\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"File not found: {path}\")\n",
    "\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        sentences = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0b3022",
   "metadata": {},
   "source": [
    "## Load Corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9592c226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medical corpus: 3021 sentences\n",
      "Press corpus: 38548 sentences\n"
     ]
    }
   ],
   "source": [
    "medical_sentences = load_corpus(MEDICAL_CORPUS)\n",
    "press_sentences = load_corpus(PRESS_CORPUS)\n",
    "\n",
    "print(f\"Medical corpus: {len(medical_sentences)} sentences\")\n",
    "print(f\"Press corpus: {len(press_sentences)} sentences\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a5e7ca",
   "metadata": {},
   "source": [
    "## Example sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57185fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example sentence from the medical corpus:\n",
      "\n",
      "EMEA / H / C / 551\n",
      "\n",
      "Example sentence from the press corpus:\n",
      "\n",
      "Patricia Martin , que voici , que voilà ! oh , bonjour Nicolas Stoufflet .\n"
     ]
    }
   ],
   "source": [
    "print(\"Example sentence from the medical corpus:\\n\")\n",
    "print(medical_sentences[0])\n",
    "\n",
    "print(\"\\nExample sentence from the press corpus:\\n\")\n",
    "print(press_sentences[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d8d89b",
   "metadata": {},
   "source": [
    "## Sentence length analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f2a48cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medical corpus statistics:\n",
      "  Average sentence length: 17.17841774246938\n",
      "  Maximum sentence length: 121\n",
      "\n",
      "Press corpus statistics:\n",
      "  Average sentence length: 32.467598837812595\n",
      "  Maximum sentence length: 617\n"
     ]
    }
   ],
   "source": [
    "def sentence_lengths(sentences):\n",
    "    return [len(sentence.split()) for sentence in sentences]\n",
    "\n",
    "med_lengths = sentence_lengths(medical_sentences)\n",
    "press_lengths = sentence_lengths(press_sentences)\n",
    "\n",
    "print(\"Medical corpus statistics:\")\n",
    "print(\"  Average sentence length:\", np.mean(med_lengths))\n",
    "print(\"  Maximum sentence length:\", np.max(med_lengths))\n",
    "\n",
    "print(\"\\nPress corpus statistics:\")\n",
    "print(\"  Average sentence length:\", np.mean(press_lengths))\n",
    "print(\"  Maximum sentence length:\", np.max(press_lengths))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadb6274",
   "metadata": {},
   "source": [
    "## Vocabulary construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51a31c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medical vocabulary size: 9104\n",
      "Press vocabulary size: 39654\n"
     ]
    }
   ],
   "source": [
    "def build_vocabulary(sentences):\n",
    "    tokens = []\n",
    "    for sentence in sentences:\n",
    "        tokens.extend(sentence.split())\n",
    "    return Counter(tokens)\n",
    "\n",
    "medical_vocab = build_vocabulary(medical_sentences)\n",
    "press_vocab = build_vocabulary(press_sentences)\n",
    "\n",
    "print(\"Medical vocabulary size:\", len(medical_vocab))\n",
    "print(\"Press vocabulary size:\", len(press_vocab))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413fd454",
   "metadata": {},
   "source": [
    "## Most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a1d7416f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent words in the medical corpus:\n",
      ". 2905\n",
      "de 2506\n",
      ", 1159\n",
      "la 1103\n",
      "' 1082\n",
      "et 892\n",
      "des 869\n",
      "l 849\n",
      "’ 815\n",
      "d 757\n",
      "\n",
      "Most frequent words in the press corpus:\n",
      ", 70810\n",
      "de 54090\n",
      ". 38523\n",
      "la 32421\n",
      "le 27993\n",
      "l' 23717\n",
      "à 23219\n",
      "et 21367\n",
      "les 21308\n",
      "est 17170\n"
     ]
    }
   ],
   "source": [
    "print(\"Most frequent words in the medical corpus:\")\n",
    "for word, freq in medical_vocab.most_common(10):\n",
    "    print(word, freq)\n",
    "\n",
    "print(\"\\nMost frequent words in the press corpus:\")\n",
    "for word, freq in press_vocab.most_common(10):\n",
    "    print(word, freq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46144460",
   "metadata": {},
   "source": [
    "## Target words analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca3a359b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of candidate words:\n",
      "\n",
      "patient      | Medical:     33 | Press:     11\n",
      "traitement   | Medical:    251 | Press:     53\n",
      "maladie      | Medical:     65 | Press:    114\n",
      "solution     | Medical:     67 | Press:    100\n",
      "jaune        | Medical:      9 | Press:     23\n"
     ]
    }
   ],
   "source": [
    "candidate_words = [\"patient\", \"traitement\", \"maladie\", \"solution\", \"jaune\"]\n",
    "\n",
    "print(\"Frequency of candidate words:\\n\")\n",
    "for word in candidate_words:\n",
    "    print(f\"{word:12s} | Medical: {medical_vocab[word]:6d} | Press: {press_vocab[word]:6d}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d73ca9",
   "metadata": {},
   "source": [
    "## Vocabulary overlap & OOV analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "748e082c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words only in medical corpus: 5351\n",
      "Words only in press corpus: 35901\n"
     ]
    }
   ],
   "source": [
    "medical_only = set(medical_vocab.keys()) - set(press_vocab.keys())\n",
    "press_only = set(press_vocab.keys()) - set(medical_vocab.keys())\n",
    "\n",
    "print(\"Words only in medical corpus:\", len(medical_only))\n",
    "print(\"Words only in press corpus:\", len(press_only))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1bf93a",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This corpus exploration highlights strong contrasts between the two datasets:\n",
    "\n",
    "- The **medical corpus** is smaller, highly specialized, and contains domain-specific terminology.\n",
    "- The **press corpus** is much larger, more diverse, and covers general language usage.\n",
    "- Vocabulary size and sentence length distributions differ significantly.\n",
    "\n",
    "These observations motivate:\n",
    "- training **separate word embeddings** for each corpus,\n",
    "- comparing **Word2Vec (CBOW, Skip-gram)** and **FastText**,\n",
    "- evaluating how corpus domain and size impact semantic similarity,\n",
    "- and later assessing their impact on **NER performance in TP2**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7587eb7c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
