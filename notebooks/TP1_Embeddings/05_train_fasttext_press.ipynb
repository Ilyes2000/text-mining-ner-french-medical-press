{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9edaf11",
   "metadata": {},
   "source": [
    "# TP1 Word Embeddings  \n",
    "## Training FastText on the Press Corpus (QUAERO_FrenchPress)\n",
    "\n",
    "In this notebook, we train **FastText word embeddings** on the large\n",
    "general-domain corpus **QUAERO_FrenchPress**.\n",
    "\n",
    "FastText extends Word2Vec by representing words as a sum of\n",
    "**character n-grams**, which allows:\n",
    "- better modeling of morphology,\n",
    "- robustness to rare and unseen words,\n",
    "- richer representations for large vocabularies.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe1c52c",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cae27f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "from gensim.models import FastText\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe9660c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press corpus path: /Users/ilyessais/Documents/Lab M2/Text Mining & Chatbots/text-mining-chatbots-lab3/TP_ISD2020/data/embeddings_corpus/QUAERO_FrenchPress/QUAERO_FrenchPress_traindev.ospl\n",
      "Embeddings directory: /Users/ilyessais/Documents/Lab M2/Text Mining & Chatbots/text-mining-chatbots-lab3/TP_ISD2020/embeddings\n"
     ]
    }
   ],
   "source": [
    "CURRENT_DIR = os.getcwd()\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(CURRENT_DIR, \"../..\"))\n",
    "\n",
    "PRESS_CORPUS_PATH = os.path.join(\n",
    "    PROJECT_ROOT,\n",
    "    \"data\",\n",
    "    \"embeddings_corpus\",\n",
    "    \"QUAERO_FrenchPress\",\n",
    "    \"QUAERO_FrenchPress_traindev.ospl\"\n",
    ")\n",
    "\n",
    "EMBEDDINGS_DIR = os.path.join(PROJECT_ROOT, \"embeddings\")\n",
    "os.makedirs(EMBEDDINGS_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Press corpus path:\", PRESS_CORPUS_PATH)\n",
    "print(\"Embeddings directory:\", EMBEDDINGS_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9854da",
   "metadata": {},
   "source": [
    "## Load and Tokenize Press Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e835512e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of press sentences: 38548\n",
      "Example tokenized sentence:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Patricia',\n",
       " 'Martin',\n",
       " ',',\n",
       " 'que',\n",
       " 'voici',\n",
       " ',',\n",
       " 'que',\n",
       " 'voilà',\n",
       " '!',\n",
       " 'oh',\n",
       " ',',\n",
       " 'bonjour',\n",
       " 'Nicolas',\n",
       " 'Stoufflet',\n",
       " '.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_tokenized_corpus(path):\n",
    "    sentences = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                sentences.append(line.split())\n",
    "    return sentences\n",
    "\n",
    "\n",
    "press_sentences = load_tokenized_corpus(PRESS_CORPUS_PATH)\n",
    "\n",
    "print(f\"Number of press sentences: {len(press_sentences)}\")\n",
    "print(\"Example tokenized sentence:\")\n",
    "press_sentences[0][:20]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0badca4",
   "metadata": {},
   "source": [
    "## Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2459ebb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 100\n",
      "Min count: 1\n",
      "Window size: 5\n",
      "Epochs: 10\n",
      "Workers: 12\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "MIN_COUNT = 1\n",
    "WINDOW_SIZE = 5\n",
    "EPOCHS = 10\n",
    "N_WORKERS = multiprocessing.cpu_count()\n",
    "\n",
    "print(\"Embedding dimension:\", EMBEDDING_DIM)\n",
    "print(\"Min count:\", MIN_COUNT)\n",
    "print(\"Window size:\", WINDOW_SIZE)\n",
    "print(\"Epochs:\", EPOCHS)\n",
    "print(\"Workers:\", N_WORKERS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1de71f",
   "metadata": {},
   "source": [
    "## Train FastText CBOW (Press)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ceb9a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training FastText CBOW model on press corpus...\n",
      "FastText training completed.\n"
     ]
    }
   ],
   "source": [
    "print(\"Training FastText CBOW model on press corpus...\")\n",
    "\n",
    "fasttext_press = FastText(\n",
    "    sentences=press_sentences,\n",
    "    vector_size=EMBEDDING_DIM,\n",
    "    window=WINDOW_SIZE,\n",
    "    min_count=MIN_COUNT,\n",
    "    sg=0,             # CBOW\n",
    "    workers=N_WORKERS,\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "\n",
    "print(\"FastText training completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80afbaae",
   "metadata": {},
   "source": [
    "## Save Model and Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8355ee63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText model saved to: /Users/ilyessais/Documents/Lab M2/Text Mining & Chatbots/text-mining-chatbots-lab3/TP_ISD2020/embeddings/fasttext_press_cbow.model\n",
      "FastText vectors saved to: /Users/ilyessais/Documents/Lab M2/Text Mining & Chatbots/text-mining-chatbots-lab3/TP_ISD2020/embeddings/fasttext_press_cbow.vec\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(EMBEDDINGS_DIR, \"fasttext_press_cbow.model\")\n",
    "vectors_path = os.path.join(EMBEDDINGS_DIR, \"fasttext_press_cbow.vec\")\n",
    "\n",
    "fasttext_press.save(model_path)\n",
    "fasttext_press.wv.save_word2vec_format(vectors_path)\n",
    "\n",
    "print(\"FastText model saved to:\", model_path)\n",
    "print(\"FastText vectors saved to:\", vectors_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe4ca06",
   "metadata": {},
   "source": [
    "## Vocabulary Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63125b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText press vocabulary size: 39654\n"
     ]
    }
   ],
   "source": [
    "print(\"FastText press vocabulary size:\", len(fasttext_press.wv))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c466e2",
   "metadata": {},
   "source": [
    "## Semantic Similarity Press Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ac99381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most similar words to 'patient' (FastText – Press):\n",
      "  patientent      0.985\n",
      "  impatient       0.981\n",
      "  détient         0.975\n",
      "  ratifient       0.973\n",
      "  trient          0.972\n",
      "\n",
      "Most similar words to 'traitement' (FastText – Press):\n",
      "  promptement     0.973\n",
      "  recrutement     0.967\n",
      "  concrètement    0.965\n",
      "  farouchement    0.962\n",
      "  plafonnement    0.961\n",
      "\n",
      "Most similar words to 'maladie' (FastText – Press):\n",
      "  malnutrie       0.925\n",
      "  trilogie        0.893\n",
      "  folie           0.889\n",
      "  magie           0.888\n",
      "  pie             0.887\n",
      "\n",
      "Most similar words to 'solution' (FastText – Press):\n",
      "  révolution      0.983\n",
      "  résolution      0.982\n",
      "  évolution       0.978\n",
      "  dissolution     0.976\n",
      "  caution         0.976\n",
      "\n",
      "Most similar words to 'jaune' (FastText – Press):\n",
      "  Neptune         0.970\n",
      "  brune           0.968\n",
      "  lune            0.963\n",
      "  Jeune           0.959\n",
      "  Saâdoune        0.946\n"
     ]
    }
   ],
   "source": [
    "test_words = [\"patient\", \"traitement\", \"maladie\", \"solution\", \"jaune\"]\n",
    "\n",
    "for word in test_words:\n",
    "    print(f\"\\nMost similar words to '{word}' (FastText – Press):\")\n",
    "    for w, s in fasttext_press.wv.most_similar(word, topn=5):\n",
    "        print(f\"  {w:<15} {s:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97af195c",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "FastText embeddings trained on the press corpus:\n",
    "- capture general semantic relationships,\n",
    "- benefit from character-level information,\n",
    "- provide robust representations for a very large vocabulary.\n",
    "\n",
    "Compared to the medical corpus:\n",
    "- press embeddings are more generic,\n",
    "- medical embeddings are more specialized.\n",
    "\n",
    "These results confirm the strong impact of **training data domain**\n",
    "on word embeddings and motivate their evaluation on downstream tasks,\n",
    "such as Named Entity Recognition in TP2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed1e38d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
