{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e249376",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f8d0480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import FastText, KeyedVectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3b7bd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final NER datasets\n",
    "DATA_DIR = \"../../data/ner_processed/final\"\n",
    "\n",
    "TRAIN_PATH = os.path.join(DATA_DIR, \"emea_train.csv\")\n",
    "DEV_PATH   = os.path.join(DATA_DIR, \"emea_dev.csv\")\n",
    "TEST_PATH  = os.path.join(DATA_DIR, \"emea_test.csv\")\n",
    "\n",
    "# FastText model trained in TP1 (medical corpus)\n",
    "FASTTEXT_MODEL_PATH = \"../../embeddings/fasttext_medical_cbow.model\"\n",
    "\n",
    "EMBEDDING_DIM = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b291f5fc",
   "metadata": {},
   "source": [
    "## Load NER datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a380da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (706, 2)\n",
      "Dev size: (649, 2)\n",
      "Test size: (578, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRIALT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EMEA / H / C / 551</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Qu ’ est ce que Prialt ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prialt est une solution pour perfusion contena...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dans quel cas Prialt est - il utilisé ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label\n",
       "0                                             PRIALT      1\n",
       "1                                 EMEA / H / C / 551      0\n",
       "2                           Qu ’ est ce que Prialt ?      1\n",
       "3  Prialt est une solution pour perfusion contena...      1\n",
       "4            Dans quel cas Prialt est - il utilisé ?      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "dev_df   = pd.read_csv(DEV_PATH)\n",
    "test_df  = pd.read_csv(TEST_PATH)\n",
    "\n",
    "print(\"Train size:\", train_df.shape)\n",
    "print(\"Dev size:\", dev_df.shape)\n",
    "print(\"Test size:\", test_df.shape)\n",
    "\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019aa1e4",
   "metadata": {},
   "source": [
    "## Load FastText model (medical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a12fb246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText vocabulary size: 9104\n",
      "Embedding dimension: 100\n"
     ]
    }
   ],
   "source": [
    "fasttext_model = FastText.load(FASTTEXT_MODEL_PATH)\n",
    "ft = fasttext_model.wv\n",
    "\n",
    "print(\"FastText vocabulary size:\", len(ft))\n",
    "print(\"Embedding dimension:\", ft.vector_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5f9e9a",
   "metadata": {},
   "source": [
    "## Vocabulary coverage analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ab39c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER vocabulary size: 2599\n",
      "Covered words: 2599\n",
      "OOV words: 0\n",
      "Coverage ratio: 100.00%\n"
     ]
    }
   ],
   "source": [
    "def get_vocab_from_df(df):\n",
    "    vocab = set()\n",
    "    for sent in df[\"review\"]:\n",
    "        for w in sent.split():\n",
    "            vocab.add(w)\n",
    "    return vocab\n",
    "\n",
    "train_vocab = get_vocab_from_df(train_df)\n",
    "\n",
    "covered = [w for w in train_vocab if w in ft]\n",
    "oov = [w for w in train_vocab if w not in ft]\n",
    "\n",
    "print(f\"NER vocabulary size: {len(train_vocab)}\")\n",
    "print(f\"Covered words: {len(covered)}\")\n",
    "print(f\"OOV words: {len(oov)}\")\n",
    "print(f\"Coverage ratio: {len(covered) / len(train_vocab):.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af90b891",
   "metadata": {},
   "source": [
    "## Inspect FastText semantic behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cc25521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most similar words to 'patient':\n",
      "  Patient         0.999\n",
      "  tremblements    0.999\n",
      "  pansements      0.999\n",
      "  patiente        0.999\n",
      "  Tremblements    0.999\n",
      "\n",
      "Most similar words to 'traitement':\n",
      "  Traitement      1.000\n",
      "  Taaitement      1.000\n",
      "  Allaitement     0.999\n",
      "  allaitement     0.999\n",
      "  traitements     0.999\n",
      "\n",
      "Most similar words to 'maladie':\n",
      "  Maladie         1.000\n",
      "  malade          1.000\n",
      "  professionnelle 1.000\n",
      "  professionnel   1.000\n",
      "  hyrgathione     1.000\n",
      "\n",
      "Most similar words to 'solution':\n",
      "  Dissolution     1.000\n",
      "  évolution       0.999\n",
      "  dilution        0.999\n",
      "  Solution        0.999\n",
      "  Evolution       0.999\n"
     ]
    }
   ],
   "source": [
    "medical_words = [\"patient\", \"traitement\", \"maladie\", \"solution\"]\n",
    "\n",
    "for word in medical_words:\n",
    "    print(f\"\\nMost similar words to '{word}':\")\n",
    "    for w, s in ft.most_similar(word, topn=5):\n",
    "        print(f\"  {w:15s} {s:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054591da",
   "metadata": {},
   "source": [
    "## Medical Training command (CNN + FastText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a00c068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading files...\n",
      "Merging files...\n",
      "Building vocab...\n",
      "Encoding reviews...\n",
      "100%|█████████████████████████████████████| 706/706 [00:00<00:00, 365984.26it/s]\n",
      "100%|█████████████████████████████████████| 578/578 [00:00<00:00, 440542.92it/s]\n",
      "100%|█████████████████████████████████████| 649/649 [00:00<00:00, 452477.28it/s]\n",
      "[OK] Vocabulary saved to ../../data/ner_processed/final/emea_train.csv_vocab.pkl\n",
      "Vocabulary size: 4590\n",
      "Feature Shapes:\n",
      "===============\n",
      "Train set: (706, 128)\n",
      "Validation set: (578, 128)\n",
      "Test set: (649, 128)\n",
      "Taille vocabulaire 4590\n",
      "SentimentModelCNN(\n",
      "  (embed): Embedding(4590, 100)\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(1, 100, kernel_size=(3, 100), stride=(1, 1))\n",
      "    (1): Conv2d(1, 100, kernel_size=(4, 100), stride=(1, 1))\n",
      "    (2): Conv2d(1, 100, kernel_size=(5, 100), stride=(1, 1))\n",
      "  )\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (fc1): Linear(in_features=300, out_features=2, bias=True)\n",
      ")\n",
      "Training:   0%|                      | 0/25 [00:00<?, ?it/s, Training batch 0/6]/opt/anaconda3/lib/python3.13/site-packages/torch/nn/_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "Epoch 1/25 | Train Loss: 50.008 Train Acc: 0.561 | Val Loss: 38.842 Val Acc: 0.880\n",
      "Epoch 2/25 | Train Loss: 36.881 Train Acc: 0.813 | Val Loss: 34.418 Val Acc: 0.885\n",
      "Epoch 3/25 | Train Loss: 31.625 Train Acc: 0.882 | Val Loss: 33.284 Val Acc: 0.885\n",
      "Epoch 4/25 | Train Loss: 29.687 Train Acc: 0.904 | Val Loss: 32.211 Val Acc: 0.876\n",
      "Epoch 5/25 | Train Loss: 27.280 Train Acc: 0.909 | Val Loss: 30.760 Val Acc: 0.888\n",
      "Epoch 6/25 | Train Loss: 25.681 Train Acc: 0.916 | Val Loss: 29.856 Val Acc: 0.891\n",
      "Epoch 7/25 | Train Loss: 24.059 Train Acc: 0.929 | Val Loss: 29.435 Val Acc: 0.900\n",
      "Epoch 8/25 | Train Loss: 23.334 Train Acc: 0.927 | Val Loss: 29.229 Val Acc: 0.902\n",
      "Epoch 9/25 | Train Loss: 20.705 Train Acc: 0.946 | Val Loss: 29.063 Val Acc: 0.908\n",
      "Epoch 10/25 | Train Loss: 20.463 Train Acc: 0.940 | Val Loss: 28.918 Val Acc: 0.902\n",
      "Epoch 11/25 | Train Loss: 18.588 Train Acc: 0.945 | Val Loss: 28.795 Val Acc: 0.908\n",
      "Epoch 12/25 | Train Loss: 18.087 Train Acc: 0.935 | Val Loss: 28.689 Val Acc: 0.902\n",
      "Epoch 13/25 | Train Loss: 17.338 Train Acc: 0.947 | Val Loss: 28.417 Val Acc: 0.908\n",
      "Epoch 14/25 | Train Loss: 16.604 Train Acc: 0.947 | Val Loss: 28.213 Val Acc: 0.902\n",
      "Epoch 15/25 | Train Loss: 15.272 Train Acc: 0.958 | Val Loss: 28.178 Val Acc: 0.902\n",
      "Epoch 16/25 | Train Loss: 14.762 Train Acc: 0.960 | Val Loss: 28.258 Val Acc: 0.905\n",
      "[WARNING] Validation loss did not improved (28.178 --> 28.258)                  \n",
      "Epoch 17/25 | Train Loss: 14.595 Train Acc: 0.957 | Val Loss: 28.300 Val Acc: 0.905\n",
      "[WARNING] Validation loss did not improved (28.178 --> 28.300)                  \n",
      "Epoch 18/25 | Train Loss: 12.988 Train Acc: 0.960 | Val Loss: 28.335 Val Acc: 0.901\n",
      "[WARNING] Validation loss did not improved (28.178 --> 28.335)                  \n",
      "Epoch 19/25 | Train Loss: 12.609 Train Acc: 0.964 | Val Loss: 28.050 Val Acc: 0.899\n",
      "Epoch 20/25 | Train Loss: 11.389 Train Acc: 0.973 | Val Loss: 27.853 Val Acc: 0.904\n",
      "Epoch 21/25 | Train Loss: 10.894 Train Acc: 0.970 | Val Loss: 27.938 Val Acc: 0.899\n",
      "[WARNING] Validation loss did not improved (27.853 --> 27.938)      \n",
      "Epoch 22/25 | Train Loss: 10.812 Train Acc: 0.966 | Val Loss: 28.104 Val Acc: 0.905\n",
      "[WARNING] Validation loss did not improved (27.853 --> 28.104)      \n",
      "Epoch 23/25 | Train Loss: 9.939 Train Acc: 0.967 | Val Loss: 28.038 Val Acc: 0.902\n",
      "[WARNING] Validation loss did not improved (27.853 --> 28.038)      \n",
      "Epoch 24/25 | Train Loss: 9.496 Train Acc: 0.966 | Val Loss: 27.980 Val Acc: 0.895\n",
      "[WARNING] Validation loss did not improved (27.853 --> 27.980)      \n",
      "Epoch 25/25 | Train Loss: 8.882 Train Acc: 0.970 | Val Loss: 27.881 Val Acc: 0.898\n",
      "[WARNING] Validation loss did not improved (27.853 --> 27.881)      \n",
      "Early stopped at Epoch-25                                           \n",
      "Training:  96%|▉| 24/25 [00:15<00:00,  1.50it/s, Val Loss: 27.881 | Val Acc: 0.8\n",
      "Inference: 100%|██████████████████████████████████| 6/6 [00:00<00:00, 48.25it/s]\n",
      "Accuracy: 0.8627, Loss: 36.0458\n",
      "Inference: 100%|██████████████████████████████████| 6/6 [00:00<00:00, 49.89it/s]\n",
      "\n",
      "========== TEST RESULTS ==========\n",
      "Model      : CNN\n",
      "Precision  : 0.8587\n",
      "Recall     : 0.9945\n",
      "F1-score   : 0.9217\n",
      "Accuracy   : 0.8567\n",
      "\n",
      "Detailed classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.09      0.16        99\n",
      "           1       0.86      0.99      0.92       550\n",
      "\n",
      "    accuracy                           0.86       649\n",
      "   macro avg       0.80      0.54      0.54       649\n",
      "weighted avg       0.84      0.86      0.81       649\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.75      0.16        12\n",
      "           1       0.99      0.86      0.92       637\n",
      "\n",
      "    accuracy                           0.86       649\n",
      "   macro avg       0.54      0.80      0.54       649\n",
      "weighted avg       0.98      0.86      0.91       649\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ../../scripts/cnn_classification.py \\\n",
    "    --model cnn \\\n",
    "    --train ../../data/ner_processed/final/emea_train.csv \\\n",
    "    --valid ../../data/ner_processed/final/emea_dev.csv \\\n",
    "    --test ../../data/ner_processed/final/emea_test.csv \\\n",
    "    --epochs 25\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac6f3db",
   "metadata": {},
   "source": [
    "## Press Training command (CNN + FastText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce5dde69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading files...\n",
      "Merging files...\n",
      "Building vocab...\n",
      "Encoding reviews...\n",
      "100%|█████████████████████████████████| 35723/35723 [00:00<00:00, 261649.15it/s]\n",
      "100%|███████████████████████████████████| 2880/2880 [00:00<00:00, 269459.40it/s]\n",
      "100%|███████████████████████████████████| 2825/2825 [00:00<00:00, 256120.63it/s]\n",
      "[OK] Vocabulary saved to ../../data/ner_processed/final/press_train_final.csv_vocab.pkl\n",
      "Vocabulary size: 32002\n",
      "Feature Shapes:\n",
      "===============\n",
      "Train set: (35723, 128)\n",
      "Validation set: (2880, 128)\n",
      "Test set: (2825, 128)\n",
      "Taille vocabulaire 32002\n",
      "SentimentModelCNN(\n",
      "  (embed): Embedding(32002, 100)\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(1, 100, kernel_size=(3, 100), stride=(1, 1))\n",
      "    (1): Conv2d(1, 100, kernel_size=(4, 100), stride=(1, 1))\n",
      "    (2): Conv2d(1, 100, kernel_size=(5, 100), stride=(1, 1))\n",
      "  )\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (fc1): Linear(in_features=300, out_features=2, bias=True)\n",
      ")\n",
      "Training:   0%|                    | 0/25 [00:00<?, ?it/s, Training batch 0/280]/opt/anaconda3/lib/python3.13/site-packages/torch/nn/_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "Epoch 1/25 | Train Loss: 66.826 Train Acc: 0.617 | Val Loss: 78.671 Val Acc: 0.661\n",
      "Epoch 2/25 | Train Loss: 59.101 Train Acc: 0.688 | Val Loss: 73.200 Val Acc: 0.666\n",
      "Epoch 3/25 | Train Loss: 54.315 Train Acc: 0.736 | Val Loss: 72.147 Val Acc: 0.701\n",
      "Epoch 4/25 | Train Loss: 50.057 Train Acc: 0.764 | Val Loss: 69.774 Val Acc: 0.712\n",
      "Epoch 5/25 | Train Loss: 47.151 Train Acc: 0.778 | Val Loss: 67.546 Val Acc: 0.712\n",
      "Epoch 6/25 | Train Loss: 43.804 Train Acc: 0.797 | Val Loss: 66.495 Val Acc: 0.716\n",
      "Epoch 7/25 | Train Loss: 41.347 Train Acc: 0.811 | Val Loss: 65.703 Val Acc: 0.715\n",
      "Epoch 8/25 | Train Loss: 39.021 Train Acc: 0.827 | Val Loss: 65.011 Val Acc: 0.730\n",
      "Epoch 9/25 | Train Loss: 36.591 Train Acc: 0.842 | Val Loss: 64.667 Val Acc: 0.729\n",
      "Epoch 10/25 | Train Loss: 34.750 Train Acc: 0.844 | Val Loss: 64.365 Val Acc: 0.729\n",
      "Epoch 11/25 | Train Loss: 32.878 Train Acc: 0.848 | Val Loss: 63.637 Val Acc: 0.734\n",
      "Epoch 12/25 | Train Loss: 30.965 Train Acc: 0.859 | Val Loss: 62.969 Val Acc: 0.739\n",
      "Epoch 13/25 | Train Loss: 29.274 Train Acc: 0.871 | Val Loss: 63.755 Val Acc: 0.748\n",
      "[WARNING] Validation loss did not improved (62.969 --> 63.755)                  \n",
      "Epoch 14/25 | Train Loss: 27.624 Train Acc: 0.880 | Val Loss: 62.577 Val Acc: 0.743\n",
      "Epoch 15/25 | Train Loss: 25.984 Train Acc: 0.886 | Val Loss: 62.161 Val Acc: 0.743\n",
      "Epoch 16/25 | Train Loss: 24.775 Train Acc: 0.894 | Val Loss: 62.306 Val Acc: 0.750\n",
      "[WARNING] Validation loss did not improved (62.161 --> 62.306)                  \n",
      "Epoch 17/25 | Train Loss: 23.323 Train Acc: 0.900 | Val Loss: 62.081 Val Acc: 0.749\n",
      "Epoch 18/25 | Train Loss: 22.000 Train Acc: 0.906 | Val Loss: 62.246 Val Acc: 0.751\n",
      "[WARNING] Validation loss did not improved (62.081 --> 62.246)                  \n",
      "Epoch 19/25 | Train Loss: 20.600 Train Acc: 0.911 | Val Loss: 62.850 Val Acc: 0.758\n",
      "[WARNING] Validation loss did not improved (62.081 --> 62.850)                  \n",
      "Epoch 20/25 | Train Loss: 19.445 Train Acc: 0.918 | Val Loss: 62.781 Val Acc: 0.757\n",
      "[WARNING] Validation loss did not improved (62.081 --> 62.781)                  \n",
      "Epoch 21/25 | Train Loss: 18.501 Train Acc: 0.922 | Val Loss: 62.914 Val Acc: 0.764\n",
      "[WARNING] Validation loss did not improved (62.081 --> 62.914)      \n",
      "Epoch 22/25 | Train Loss: 17.471 Train Acc: 0.927 | Val Loss: 63.209 Val Acc: 0.767\n",
      "[WARNING] Validation loss did not improved (62.081 --> 63.209)      \n",
      "Early stopped at Epoch-22                                           \n",
      "Training:  84%|▊| 21/25 [11:11<02:07, 31.97s/it, Val Loss: 63.209 | Val Acc: 0.7\n",
      "Inference: 100%|████████████████████████████████| 23/23 [00:00<00:00, 34.03it/s]\n",
      "Accuracy: 0.7863, Loss: 46.3872\n",
      "Inference: 100%|████████████████████████████████| 23/23 [00:00<00:00, 31.76it/s]\n",
      "\n",
      "========== TEST RESULTS ==========\n",
      "Model      : CNN\n",
      "Precision  : 0.8637\n",
      "Recall     : 0.8888\n",
      "F1-score   : 0.8761\n",
      "Accuracy   : 0.8159\n",
      "\n",
      "Detailed classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.62      0.64       757\n",
      "           1       0.86      0.89      0.88      2068\n",
      "\n",
      "    accuracy                           0.82      2825\n",
      "   macro avg       0.77      0.75      0.76      2825\n",
      "weighted avg       0.81      0.82      0.81      2825\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.67      0.64       697\n",
      "           1       0.89      0.86      0.88      2128\n",
      "\n",
      "    accuracy                           0.82      2825\n",
      "   macro avg       0.75      0.77      0.76      2825\n",
      "weighted avg       0.82      0.82      0.82      2825\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ../../scripts/cnn_classification.py \\\n",
    "    --model cnn \\\n",
    "    --train ../../data/ner_processed/final/press_train_final.csv \\\n",
    "    --valid ../../data/ner_processed/final/press_dev_final.csv \\\n",
    "    --test ../../data/ner_processed/final/press_test_final.csv \\\n",
    "    --epochs 25\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
